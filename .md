A/B testing involves comparing two versions of an element to see which performs better. 
For instance, this method can determine which video version gains more views or which caption leads to a higher Click-Through Rate (CTR). 
For this analysis, I am using an A/B Testing Dataset from Kaggle(https://www.kaggle.com/datasets/amirmotefaker/ab-testing-dataset/data) from Kaggle to perform A/B Test.].


### Import library
```py
import pandas as pd
import numpy as np
import scipy.stats as stats
```
### Load data
```py
# import control group
control_group = pd.read_csv('AB Testing/control_group.csv', sep = ';')

# import test group
test_group = pd.read_csv('AB Testing/test_group.csv', sep = ';')
```

### Data cleaning and processing
```py
control_group.info()
test_group.info()
```
The `.info()` result shows that the date data type is `object`, which is incorrect for a date type. Regarding completeness, the test group is complete, with no missing values (NaNs). 
However, the control group is missing one record in each of the following columns: 
Impressions, Reach, Website Clicks, Searches, View Content, Add to Cart, and Purchase, totaling seven missing values.
```py
# check nan
control_group.isna().sum()
```
Let's convert the date type from `object` to `datetime64[ns]` first. 
Since the date value isn't in ISO 8601 (YYYY-MM-DD) format, we need to add the parameter `format = '%d.%m.%Y'`.
```py
# convert date to date type
control_group['Date'] = pd.to_datetime(control_group['Date'], format = '%d.%m.%Y')
test_group['Date'] = pd.to_datetime(test_group['Date'], format = '%d.%m.%Y')
```
I plotted box plots to see if the data is normally or skewed distributed, 
so I can decide whether the mean or median should be used for imputation. 
I selected three columns to observe the trend: mpressions, Reach and Website Clicks.
```py
control_group[['# of Impressions','Reach','# of Website Clicks']].plot(kind='box');
```
![Box plot](https://raw.githubusercontent.com/bbamyaphatt/project/main/images/box%20plot.png)

We can see that all three box plots are skewed. 
Impressions and Reach have a right skew, while Website Clicks has a left skew. 
Therefore, I will choose the median to perform the imputation.

```py
# filter nan column

filter_nan_cols = [
    '# of Impressions',
    'Reach',
    '# of Website Clicks',
    '# of Searches',
    '# of View Content',
    '# of Add to Cart',
    '# of Purchase']

for col in filter_nan_cols:
    if control_group[col].isna().any():
        median_control_col = control_group[col].median()
        control_group[col].fillna(value = median_control_col, inplace = True)
        print(f"NaN in {col} replaced by {median_control_col}")
    else:
        print(f"No NaN in {col}")
```
I first filtered the columns that contain missing values and then used a for loop to fill them. 
If the loop finds a missing value in any of these columns, it calculates the median for that specific column using .median(). Subsequently, 
that missing value is filled with the calculated median. 
The inplace = True parameter instructs Python to apply these new values directly to the original DataFrame.

## Metric and hypothesis

- H0: The CTR of the control group is equal to the CTR of the test group.
- H1: The CTR of the control group is not equal to the CTR of the test group.
### Perform A/B Test
```py
# create function
def ab_test(total_control_click, total_control_impression,
            total_test_click, total_test_impression,
            signigicant_level = 0.05):
    
    # calculate conversion rate
    control_conv_rate = total_control_click / total_control_impression
    test_conv_rate = total_test_click / total_test_impression

    # calculate absolute and relative diff
    absolute_diff = test_conv_rate - control_conv_rate
    relative_diff = absolute_diff / control_conv_rate

    # calculate pooled proportion
    pooled_prop = (total_control_click + total_test_click) / (total_control_impression + total_test_impression)

    # calculate pooled standard error
    pooled_se = np.sqrt(pooled_prop * (1-pooled_prop) * (1/total_control_impression + 1/total_test_impression))

    # calculate z-score
    z_score = absolute_diff / pooled_se

    # calculate p-value (two-tailed)
    p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))

    # calculate individual se for ci
    control_se_for_ci = np.sqrt(control_conv_rate * (1 - control_conv_rate) / total_control_impression)
    test_se_for_ci = np.sqrt(test_conv_rate * (1-test_conv_rate) / total_test_impression)

    # calculate unpooled for ci
    unpooled_se = np.sqrt(control_se_for_ci**2 + test_se_for_ci**2)

    # calculate confident interval
    z_critical = stats.norm.ppf(1 - signigicant_level / 2)
    margin_error = z_critical * unpooled_se
    upper_ci = absolute_diff + margin_error
    lower_ci = absolute_diff - margin_error

    # determine if result is significant
    is_sig = p_value < signigicant_level

    return {
        'control conversion rate': control_conv_rate,
        'test conversion rate': test_conv_rate,
        'absolute diff': absolute_diff,
        'relative diff': relative_diff * 100,
        'z-score': z_score,
        'p-value': p_value,
        'lower ci': lower_ci,
        'upper ci': upper_ci,
        'is significant': is_sig
    }
```
```py
# find total click and impression
# control
total_control_click = control_group['# of Website Clicks'].sum()
total_control_impression = control_group['# of Impressions'].sum()

# test
total_test_click = test_group['# of Website Clicks'].sum()
total_test_impression = test_group['# of Impressions'].sum()

print(f"total control click: {total_control_click}\n"
      f"total control impression: {total_control_impression}\n"
      f"total test click: {total_test_click}\n"
      f"total test impression: {total_test_impression}")
```

- total control click: 159527.0
- total control impression: 3290663.0
- total test click: 180970
- total test impression: 2237544
```py
ab_test(159527, 3290663, 180970, 2237544, signigicant_level=0.05)
```
The results are below:
![A/B testing result](https://raw.githubusercontent.com/bbamyaphatt/project/main/images/AB%20Testing%20Result.png)
- The **control conversion rate is 0.048**, while the **test conversion rate is 0.081**. The **absolute difference** between these is **0.032 percentage points**.
Considering this, the test conversion rate shows a strong positive impact compared to the control, with a **relative difference of 66.83%**.
- The **Z-score is 155.53**, which is **extremely high**. This indicates that the observed difference between the control and test conversion rates is more than 155 standard errors away from zero.
- **A P-value of 0.0** is expected with such a high Z-score. This shows that a p-value less than 0.05 means the difference between these two groups is statistically significant and unlikely due to random chance.
- The **95% confidence interval** for the absolute difference is **[0.0319 - 0.0328]**. This means we are 95% confident that the true difference in conversion rates between the populations lies within this range.
Since the entire interval is above zero, it indicates that the test group performed significantly better than the control group. The fact that the interval does not include zero further confirms that this difference is not due to random chance.
- Both the p-value and the confidence interval directly align and provide strong evidence to reject the null hypothesis (H0)
  
### Conclusion
From the above results, we can draw a conclusion that using the new CTA version can significantly increase CTRs. 
The absolute difference between the two groups is 0.032 percentage points, representing a relative difference of 66.83%. 
A P-value of 0.0 and a 95% confidence interval lying in the range [0.0319 - 0.0328], not including zero, indicate that this is not due to random chance.

Increasing CTRs doesn't solely rely on the method of writing captions, but also involves factors like CTA, layout, headlines, quality of images and videos, and more. 
We can statistically test these by performing A/B methods to find which approaches are most beneficial for the business.
